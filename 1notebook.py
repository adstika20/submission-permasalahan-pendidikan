# -*- coding: utf-8 -*-
"""1notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fUxFtJbxpiiqu_G7Qf3jmsMsCu1CKg9z

# Proyek Akhir: Menyelesaikan Permasalahan Perusahaan Edutech

- Nama:Ades Tikaningsih
- Email:adestika123@gmail.com
- Id Dicoding:

## Persiapan

### Menyiapkan library yang dibutuhkan
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import joblib
#random forest
from sklearn.ensemble import RandomForestClassifier
#svm
from sklearn.svm import SVC
#knn
from sklearn.neighbors import KNeighborsClassifier
#metric
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

"""### Menyiapkan data yang akan diguankan

## Data Understanding
"""

data = pd.read_csv('https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/students_performance/data.csv', delimiter=";")

data.head()

data.shape

data.info()

# cek missing value
data.isnull().sum()

data.shape

data.iloc[:, :10].info()

# Cek variabel 1-10
data.iloc[:, :10].describe()

# Cek variabel 11-20
data.iloc[:, 10:20].describe()

data[data['Mothers_occupation'] > 25]
data[data['Fathers_occupation'] > 25]

# Cek variabel 21-30
data.iloc[:, 20:30].describe()

# Cek variabel 31-37
data.iloc[:, 30:37].describe()

"""## Data Preparation / Preprocessing"""

# ubah 3 kolom tipe data float menjadi int
columns_to_convert = ['Previous_qualification_grade', 'Admission_grade', 'Curricular_units_1st_sem_grade',
                      'Curricular_units_2nd_sem_grade', 'Unemployment_rate', 'Inflation_rate', 'GDP']
data[columns_to_convert] = data[columns_to_convert].astype('int')

data.info()

data['Status'].value_counts()

# ubah kolom status
le = LabelEncoder()
data['Status'] = le.fit_transform(data['Status'])

data['Status'].value_counts()

"""#### Standard Scaling (Standarisasi):

"""

data['Previous_qualification_grade'].value_counts()

numeric_columns = data.select_dtypes(include=['float64', 'float32']).columns
print("Kolom dengan data numerik kontinyu:")
print(numeric_columns.tolist())

# List kolom numerik kontinyu
numeric_columns = ['Previous_qualification_grade', 'Admission_grade',
                   'Curricular_units_1st_sem_grade', 'Curricular_units_2nd_sem_grade',
                   'Unemployment_rate', 'Inflation_rate', 'GDP']

# Membuat objek scaler
scaler = StandardScaler()

# Melakukan standarisasi
data_scaled = data.copy()  # Salin data asli untuk menjaga integritas
data_scaled[numeric_columns] = scaler.fit_transform(data[numeric_columns])

# Overwrite dataset asli jika diinginkan
data[numeric_columns] = data_scaled[numeric_columns]

# Menyimpan dataset ke file CSV baru
data.to_csv('dataset_standarized.csv', index=False)

print("Dataset telah disimpan dengan nama 'dataset_standarized.csv'.")

# Menampilkan data hasil standarisasi
print("Data setelah standarisasi:")
print(data_scaled[numeric_columns].head())

"""## Exploratory Data Analysis (EDA)"""

# Korelasi semua variabel terhadap variabel status
plt.figure(figsize=(20, 8))
sns.heatmap(data.corr()[['Status']].sort_values(by='Status', ascending=False), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation of Variables with 'Status'")
plt.show()

"""#### EDA Univariate (Analisis Univariat)"""

# Melihat distribusi kolom 'status'
plt.figure(figsize=(8, 6))
sns.countplot(x='Status', data=data, palette='Set2')
plt.title('Distribusi Status Mahasiswa')
plt.xlabel('Status')
plt.ylabel('Jumlah Mahasiswa')
plt.show()

"""Graduate = 2
Dropout = 0
Enrolled = 1
"""

data['Admission_grade'].hist(bins=20)

"""#### EDA Multivariate (Analisis Multivariat)

Melihat distribusi analisis 5 variabel teratas yang berkorelasi tinggi dengan variabel 'Status'
"""

# Visualisasi distribusi nilai jumlah mata kuliah yang berhasil lulus/disetujui di semester 2
plt.figure(figsize=(10, 6))
sns.boxplot(data=data, x='Status', y='Curricular_units_2nd_sem_approved', palette='pastel')
plt.title('Distribusi jumlah mata kuliah  Semester 2 berdasarkan Status Mahasiswa')
plt.ylabel('Nilai jumlah mata kuliah  Semester 2')
plt.xlabel('Status Mahasiswa')
plt.show()

# Visualisasi distribusi nilai rata-rata yang diperoleh mahasiswa untuk semua mata kuliah di semester 2
plt.figure(figsize=(10, 6))
sns.boxplot(data=data, x='Status', y='Curricular_units_2nd_sem_grade', palette='Set2')
plt.title('Distribusi nilai rata-rata Semester 2 berdasarkan Status Mahasiswa')
plt.ylabel('nilai rata-rata Semester 2')
plt.xlabel('Status Mahasiswa')
plt.show()

# Visualisasi distribusi nilai jumlah mata kuliah yang berhasil lulus/disetujui di semester 1
plt.figure(figsize=(10, 6))
sns.boxplot(data=data, x='Status', y='Curricular_units_1st_sem_approved', palette='Set2')
plt.title('Distribusi jumlah mata kuliah Semester 1 berdasarkan Status Mahasiswa')
plt.ylabel('jumlah mata kuliah Semester 1')
plt.xlabel('Status Mahasiswa')
plt.show()

# Visualisasi distribusi nilai rata-rata semua mata kuliah di semester 1
plt.figure(figsize=(10, 6))
sns.boxplot(data=data, x='Status', y='Curricular_units_1st_sem_grade', palette='Set2')
plt.title('Distribusi nilai rata-rata semua mata kuliah di semester 1 berdasarkan Status Mahasiswa')
plt.ylabel('nilai rata-rata Semester 1')
plt.xlabel('Status Mahasiswa')
plt.show()

# Visualisasi distribusi status pembayaran biaya kuliah mahasiswa
plt.figure(figsize=(10, 6))
sns.boxplot(data=data, x='Status', y='Tuition_fees_up_to_date', palette='Set2')
plt.title('Distribusi status pembayaran biaya kuliah mahasiswa berdasarkan Status Mahasiswa')
plt.ylabel('status pembayaran biaya kuliah mahasiswa')
plt.xlabel('Status Mahasiswa')
plt.show()

# Visualisasi distribusi mahasiswa adalah penerima beasiswa atau tidak
plt.figure(figsize=(10, 6))
sns.boxplot(data=data, x='Status', y='Scholarship_holder', palette='Set2')
plt.title('Distribusi mahasiswa adalah penerima beasiswa atau tidak berdasarkan Status Mahasiswa')
plt.ylabel('mahasiswa adalah penerima beasiswa atau tidak')
plt.xlabel('Status Mahasiswa')
plt.show()

"""##### Analisis Tingkat Risiko Dropout Berdasarkan Faktor Ekonomi"""

# Menghitung rata-rata faktor ekonomi berdasarkan status
economic_factors_mean = data.groupby('Status')[['Unemployment_rate', 'Inflation_rate', 'GDP']].mean()
print("Rata-rata Faktor Ekonomi berdasarkan Status Mahasiswa:")
print(economic_factors_mean)

# Scatter plot hubungan Inflasi dan Tingkat Pengangguran berdasarkan status
sns.pairplot(data, vars=['Inflation_rate', 'Unemployment_rate', 'GDP'], hue='Status', palette='viridis', diag_kind='kde')
plt.suptitle("Hubungan Antar Faktor Ekonomi berdasarkan Status", y=1.02)
plt.show()

"""##### Analisis Rata-rata Status Dropout Berdasarkan Pekerjaan dan Kualifikasi Orang Tua"""

# Menghitung rata-rata status dropout berdasarkan pekerjaan ibu
dropout_by_mothers_occupation = data.groupby('Mothers_occupation')['Status'].apply(lambda x: (x == 0).mean())  # Changed 'status_numeric' to 'Status'
print("Tingkat Dropout Berdasarkan Pekerjaan Ibu:")
print(dropout_by_mothers_occupation)

# Menghitung rata-rata status dropout berdasarkan pekerjaan ayah
dropout_by_fathers_occupation = data.groupby('Fathers_occupation')['Status'].apply(lambda x: (x == 0).mean())
print("\nTingkat Dropout Berdasarkan Pekerjaan Ayah:")
print(dropout_by_fathers_occupation)

# Menghitung rata-rata status dropout berdasarkan kualifikasi ibu
dropout_by_mothers_qualification = data.groupby('Mothers_qualification')['Status'].apply(lambda x: (x == 0).mean())
print("\nTingkat Dropout Berdasarkan Kualifikasi Ibu:")
print(dropout_by_mothers_qualification)

# Menghitung rata-rata status dropout berdasarkan kualifikasi ayah
dropout_by_fathers_qualification = data.groupby('Fathers_qualification')['Status'].apply(lambda x: (x == 0).mean())
print("\nTingkat Dropout Berdasarkan Kualifikasi Ayah:")
print(dropout_by_fathers_qualification)

# Latar Belakang Keluarga
plt.figure(figsize=(10, 6))
sns.countplot(data=data, x='Mothers_occupation', hue='Status', palette='Set2')
plt.title('Distribusi Status Mahasiswa Berdasarkan Pekerjaan Ibu')
plt.xlabel('Pekerjaan Ibu')
plt.ylabel('Jumlah Mahasiswa')
plt.legend(title='Status', labels=['Enrolled', 'Graduated', 'Dropout'])
plt.xticks(rotation=45)
plt.show()

# Visualisasi distribusi status berdasarkan pekerjaan ayah
plt.figure(figsize=(10, 6))
sns.countplot(data=data, x='Fathers_occupation', hue='Status', palette='Set2')
plt.title('Distribusi Status Mahasiswa Berdasarkan Pekerjaan Ayah')
plt.xlabel('Pekerjaan Ayah')
plt.ylabel('Jumlah Mahasiswa')
plt.legend(title='Status', labels=['Enrolled', 'Graduated', 'Dropout'])
plt.xticks(rotation=45)
plt.show()

# Visualisasi distribusi status berdasarkan kualifikasi ibu
plt.figure(figsize=(10, 6))
sns.countplot(data=data, x='Mothers_qualification', hue='Status', palette='Set2')
plt.title('Distribusi Status Mahasiswa Berdasarkan Kualifikasi Ibu')
plt.xlabel('Kualifikasi Ibu')
plt.ylabel('Jumlah Mahasiswa')
plt.legend(title='Status', labels=['Enrolled', 'Graduated', 'Dropout'])
plt.xticks(rotation=45)
plt.show()

# Visualisasi distribusi status berdasarkan kualifikasi ayah
plt.figure(figsize=(10, 6))
sns.countplot(data=data, x='Fathers_qualification', hue='Status', palette='Set2')
plt.title('Distribusi Status Mahasiswa Berdasarkan Kualifikasi Ayah')
plt.xlabel('Kualifikasi Ayah')
plt.ylabel('Jumlah Mahasiswa')
plt.legend(title='Status', labels=['Enrolled', 'Graduated', 'Dropout'])
plt.xticks(rotation=45)
plt.show()

plt.figure(figsize=(20, 8))
sns.heatmap(data.corr()[['Status']].sort_values(by='Status', ascending=False), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation of Variables with 'Status'")
plt.show()

"""#### Pembagian Data"""

data.shape

# Pembagian data dengan rasio 80:20
train_df, test_df = train_test_split(data, test_size=0.2, random_state=42, shuffle=True)

# Reset indeks untuk menjaga konsistensi
train_df.reset_index(drop=True, inplace=True)
test_df.reset_index(drop=True, inplace=True)

# Cetak ukuran data hasil pembagian
print("Ukuran data latih:", train_df.shape)
print("Ukuran data uji:", test_df.shape)

sns.countplot(data=train_df, x="Status")
plt.show()

"""- Graduate 2
- Dropout 0
- Enrolled 1

Pada visualisasi data di atas, terlihat bahwa data latih yang kita miliki didominasi oleh kategori “Graduate”
"""

train_df.Status.value_counts()

"""### Undersampler"""

from sklearn.utils import resample
from sklearn.utils import shuffle

class_2 = train_df[(train_df.Status == 2)]
class_0 = train_df[(train_df.Status == 0)]
class_1 = train_df[(train_df.Status == 1)]

df_class_2_undersampled = resample(class_2, n_samples=643, random_state=32)
df_class_0_undersampled = resample(class_0, n_samples=643, random_state=32)
print(df_class_2_undersampled.shape)
print(df_class_0_undersampled.shape)

undersampled_train_df = pd.concat([class_1, df_class_2_undersampled]).reset_index(drop=True)
undersampled_train_df = pd.concat([undersampled_train_df, df_class_0_undersampled]).reset_index(drop=True)
undersampled_train_df = shuffle(undersampled_train_df, random_state=42)
undersampled_train_df.reset_index(drop=True, inplace=True)
undersampled_train_df.sample(5)

sns.countplot(data=undersampled_train_df, x="Status")
plt.show()

X_train = undersampled_train_df.drop(columns="Status", axis=1)
y_train = undersampled_train_df["Status"]

X_test = test_df.drop(columns="Status", axis=1)
y_test = test_df["Status"]

"""## Modeling

### Decision tree
"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

tree_model = DecisionTreeClassifier(random_state=123)

param_grid = {
    #'max_features': [None, 'sqrt', 'log2'],  # Menghapus 'auto'
    'max_depth': [5, 6, 7, 8],
    'criterion': ['gini', 'entropy']
}
CV_tree = GridSearchCV(estimator=tree_model, param_grid=param_grid, cv=5, n_jobs=-1)
CV_tree.fit(X_train, y_train)

print("best parameters: ", CV_tree.best_params_)

tree_model = DecisionTreeClassifier(
    random_state=123,
    criterion='gini',
    max_depth=8,
    #max_features='None'
)

tree_model.fit(X_train, y_train)
joblib.dump(tree_model, "/content/sample_data/model/tree_model.joblib")

y_pred = tree_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

"""### Random forest"""

from sklearn.ensemble import RandomForestClassifier

rdf_model = RandomForestClassifier(random_state=123)

param_grid = {
    'n_estimators': [200, 500],
    #'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth' : [6, 7, 8],
    'criterion' :['gini', 'entropy']
}

CV_rdf = GridSearchCV(estimator=rdf_model, param_grid=param_grid, cv=5, n_jobs=-1)
CV_rdf.fit(X_train, y_train)

print("best parameters: ", CV_rdf.best_params_)

rdf_model = RandomForestClassifier(
    random_state=123,
    max_depth=8,
    n_estimators=200,
    max_features='sqrt',
    criterion='entropy',
    n_jobs=-1
)
rdf_model.fit(X_train, y_train)
joblib.dump(rdf_model, "/content/sample_data/model/rdf_model.joblib")

y_pred_rdf = rdf_model.predict(X_test)
accuracy_rdf = accuracy_score(y_test, y_pred_rdf)
print(f"Accuracy: {accuracy_rdf:.2f}")

"""### Gradient Boosting"""

from sklearn.ensemble import GradientBoostingClassifier

gboost_model = GradientBoostingClassifier(random_state=123)

param_grid = {
    'max_depth': [5, 8],
    'n_estimators': [200, 300],
    'learning_rate': [0.01, 0.1],
    'max_features': ['sqrt', 'log2']
}

CV_gboost = GridSearchCV(estimator=gboost_model, param_grid=param_grid, cv=5, n_jobs=-1)
CV_gboost.fit(X_train, y_train)

print("best parameters: ", CV_gboost.best_params_)

gboost_model = GradientBoostingClassifier(
    random_state=123,
    learning_rate=0.01,
    max_depth=8,
    max_features='sqrt',
    n_estimators=300
)
gboost_model.fit(X_train, y_train)
joblib.dump(gboost_model, "/content/sample_data/model/gboost_model.joblib")

y_pred_gboost = gboost_model.predict(X_test)
accuracy_gboost = accuracy_score(y_test, y_pred_gboost)
print(f"Accuracy: {accuracy_gboost:.2f}")

"""## Evaluation"""

from sklearn.metrics import classification_report, confusion_matrix

"""**Decision Tree**"""

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Visualisasi Confusion Matrix dengan Heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues",
            xticklabels=['Dropout (0)', 'Graduate (1)', 'Enrolled (2)'],
            yticklabels=['Dropout (0)', 'Graduate (1)', 'Enrolled (2)'])
plt.title("Confusion Matrix Heatmap")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

# Classification Report y_pred_rdf = rdf_model.predict(X_test)
print("\nClassification Report:")
class_report = classification_report(y_test, y_pred)
print(class_report)

"""**Random Forest**"""

# Confusion Matrix
conf_matrix_rdf = confusion_matrix(y_test, y_pred_rdf)

# Visualisasi Confusion Matrix dengan Heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_rdf, annot=True, fmt="d", cmap="Blues",
            xticklabels=['Dropout (0)', 'Graduate (1)', 'Enrolled (2)'],
            yticklabels=['Dropout (0)', 'Graduate (1)', 'Enrolled (2)'])
plt.title("Confusion Matrix Random Forest")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

# Classification Report
print("\nClassification Report:")
class_report_rdf = classification_report(y_test, y_pred_rdf)
print(class_report_rdf)

"""**Gradient Boosting**"""

# Confusion Matrix
conf_matrix_gboost = confusion_matrix(y_test, y_pred_gboost)

# Visualisasi Confusion Matrix dengan Heatmap y_pred_gboost
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_gboost, annot=True, fmt="d", cmap="Blues",
            xticklabels=['Dropout (0)', 'Graduate (1)', 'Enrolled (2)'],
            yticklabels=['Dropout (0)', 'Graduate (1)', 'Enrolled (2)'])
plt.title("Confusion Matrix Gradient Boosting")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

# Classification Report
print("\nClassification Report:")
class_report_gboost = classification_report(y_test, y_pred_gboost)
print(class_report_gboost)

"""**feature importance**"""

def plot_feature_importances(feature_importances, cols):
    features = pd.DataFrame(feature_importances, columns=['coef_value']).set_index(cols)
    features = features.sort_values(by='coef_value', ascending=False)
    top_features = features

    plt.figure(figsize=(10, 6))
    sns.barplot(x='coef_value', y=features.index, data=features)
    plt.show()
    return top_features

plot_feature_importances(gboost_model.feature_importances_, X_train.columns)